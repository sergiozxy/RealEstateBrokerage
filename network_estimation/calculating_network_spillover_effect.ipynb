{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuyuan/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pybind11\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import geopandas as gpd\n",
    "import shapely \n",
    "import os\n",
    "import sys\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Point\n",
    "import random\n",
    "from geopy.distance import geodesic\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/xuyuan/Desktop/2024 summer/real estate paper/writing/RealEstateBrokerage/network_estimation')\n",
    "import network_formulation\n",
    "os.chdir('/home/xuyuan/Desktop/2024 summer/real estate paper/oritignal cleaning/RealEstateBrokerage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217200\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_stata('template.dta')\n",
    "codebook = {\n",
    "    1: '北京市',\n",
    "    2: '成都市',\n",
    "    3: '重庆市',\n",
    "    4: '广州市',\n",
    "    5: '杭州市',\n",
    "    6: '南京市',\n",
    "    7: '上海市',\n",
    "    8: '深圳市',\n",
    "    9: '天津市',\n",
    "    10: '武汉市'\n",
    "}\n",
    "\n",
    "data['city_id'] = data['city_id'].map(codebook)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'influence' in data.columns:\n",
    "    data.drop(columns = ['influence'], inplace = True)\n",
    "if 'community' in data.columns:\n",
    "    data.drop(columns = ['community'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_influential_effects(df_network, df_edges):\n",
    "    # Create a graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add nodes for stores and communities\n",
    "    stores = df_network['store_id'].unique()\n",
    "    communities = df_network['community_id'].unique()\n",
    "    for store in stores:\n",
    "        G.add_node(f'Store {store}', type='store')\n",
    "    for community in communities:\n",
    "        G.add_node(f'Community {community}', type='community')\n",
    "\n",
    "    # Add edges based on df_network\n",
    "    for _, row in df_network.iterrows():\n",
    "        store_id = f'Store {row[\"store_id\"]}'\n",
    "        community_id = f'Community {row[\"community_id\"]}'\n",
    "        effect = row['effect']\n",
    "        G.add_edge(store_id, community_id, weight=1) # we can specify the effect with weight effect\n",
    "        # print(f\"Edge added: {store_id} <-> {community_id}, Weight: {effect}\")\n",
    "\n",
    "    # Add edges based on df_edges\n",
    "    for _, row in df_edges.iterrows():\n",
    "        store_id_1 = f'Store {row[\"store_id_1\"]}'\n",
    "        store_id_2 = f'Store {row[\"store_id_2\"]}'\n",
    "        effect = row['effect']\n",
    "        G.add_edge(store_id_1, store_id_2, weight=effect)\n",
    "        # print(f\"Edge added: {store_id_1} <-> {store_id_2}, Weight: {effect}\")\n",
    "\n",
    "    # Initialize community influence\n",
    "    community_influence = {f'Community {i}.0': 0 for i in communities}\n",
    "    # BFS to propagate influence\n",
    "    # Function to propagate influence from a community through the network of stores\n",
    "    def propagate_influence(community):\n",
    "        # print(community)\n",
    "        queue = []\n",
    "        visited = set()\n",
    "\n",
    "        # Initialize the queue with stores directly connected to the community\n",
    "        for store_id in G.neighbors(community):\n",
    "            if store_id.startswith('Store'):\n",
    "                initial_effect = G[community][store_id]['weight']\n",
    "                queue.append((store_id, initial_effect)) # (store_id, cumulative_effect)\n",
    "                visited.add(store_id)\n",
    "                # print(f\"Initial: Community {community} -> Store {store_id}, Effect: {initial_effect}\")\n",
    "\n",
    "\n",
    "        # Perform BFS to propagate the influence\n",
    "        while queue:\n",
    "            current_store, current_effect = queue.pop(0)\n",
    "            for neighbor in G.neighbors(current_store):\n",
    "                if neighbor not in visited:\n",
    "                    if neighbor.startswith('Store'):\n",
    "                        # Calculate the propagated effect\n",
    "                        edge_weight = G[current_store][neighbor]['weight']\n",
    "                        new_effect = current_effect * edge_weight\n",
    "                        queue.append((neighbor, new_effect))\n",
    "                        visited.add(neighbor)\n",
    "                        # print(f\"Propagate: Store {current_store} -> Store {neighbor}, Effect: {new_effect}\")\n",
    "            # Update the influence for the initial community\n",
    "            community_influence[community] += current_effect\n",
    "            # print(f\"Accumulate: Community {community}, Current Store {current_store}, Effect: {current_effect}\")\n",
    "\n",
    "    # Calculate the influence for each community\n",
    "    for community in community_influence.keys():\n",
    "        propagate_influence(community)\n",
    "\n",
    "    return community_influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(data['city_id'].unique())):\n",
    "    map_data = data[data['city_id'] == data['city_id'].unique()[i]]\n",
    "    for j in range(0, len(map_data['year'].unique())):\n",
    "        map_data = data[(data['city_id'] == data['city_id'].unique()[i]) & (data['year'] == data['year'].unique()[j])]\n",
    "        map_data = gpd.GeoDataFrame(map_data, geometry = map_data.geometry.apply(wkt.loads))\n",
    "        df = pd.read_csv(\"classifying brokerages/processed/{}_{}.csv\".format(data['year'].unique()[j] - 2000, data['city_id'].unique()[i]))\n",
    "        map_data['longitude'] = map_data['geometry'].apply(lambda point: point.x)\n",
    "        map_data['latitude'] = map_data['geometry'].apply(lambda point: point.y)\n",
    "        \n",
    "        \n",
    "        effects = map_data['number'].values\n",
    "        stores = df[['gpsx', 'gpsy']].values.tolist()\n",
    "        communities = map_data[['longitude', 'latitude']].values.tolist()\n",
    "\n",
    "        within_distance_meters = 410.0 # this is what we find in the RD design\n",
    "        # Perform network formation\n",
    "        network, edges = network_formulation.network_formation(stores, communities, effects, within_distance_meters)\n",
    "        \n",
    "        df_edges = pd.DataFrame(edges, columns=[\"store_id_1\", \"store_id_2\", \"effect\"])\n",
    "        \n",
    "        df_network = []\n",
    "        for x, comm_effects in enumerate(network):\n",
    "            for comm, effect in comm_effects:\n",
    "                df_network.append((x, comm, effect))\n",
    "        df_network = pd.DataFrame(df_network, columns=[\"store_id\", \"community_id\", \"effect\"])\n",
    "\n",
    "\n",
    "        # Calculate the average influential effect for each community\n",
    "        community_influence = calculate_influential_effects(df_network, df_edges)\n",
    "        \n",
    "        community_influence_df = pd.DataFrame(list(community_influence.items()), columns=['community', 'influence'])\n",
    "        community_influence_df['community_id'] = community_influence_df['community'].str.extract(r'(\\d+)').astype(int)\n",
    "        \n",
    "        map_data.reset_index(drop = True, inplace = True)\n",
    "        map_data['community_id'] = map_data.index\n",
    "        merged_data = pd.merge(map_data, community_influence_df, on='community_id', how='left')\n",
    "\n",
    "        # print(len(community_influence_df['community_id'].unique()))\n",
    "        # print(merged_data['influence'].isnull().sum())\n",
    "\n",
    "        merged_data['influence'] = merged_data['influence'].fillna(0)\n",
    "        \n",
    "        if i == 0 and j == 0:\n",
    "            combined_result = merged_data\n",
    "        else:\n",
    "            combined_result = pd.concat([combined_result, merged_data], ignore_index=True, verify_integrity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building_type        0\n",
      "village              0\n",
      "district             0\n",
      "floor_level          0\n",
      "new_lng              0\n",
      "                 ...  \n",
      "longitude            0\n",
      "latitude             0\n",
      "community_id         0\n",
      "community        74466\n",
      "influence            0\n",
      "Length: 118, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(combined_result.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217200\n"
     ]
    }
   ],
   "source": [
    "print(len(combined_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_result = combined_result[['id', 'year', 'influence']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE\n",
    "\n",
    "this is the exported network effect data and we should merge it back\n",
    "\n",
    "This should be useable after the analysis part is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_result.to_csv('combined_result-with-network.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// merge the result back to the file\n",
    "\n",
    "import delimited \"to_merged_with_network.csv\", clear\n",
    "* Sort the imported CSV file by id and year\n",
    "sort id year\n",
    "\n",
    "save \"temp_csv.dta\", replace\n",
    "\n",
    "use \"template.dta\", clear\n",
    "\t\n",
    "sort id year\n",
    "\n",
    "merge 1:1 id year using \"temp_csv.dta\"\n",
    "save \"template.dta\", replace\n",
    "\n",
    "// this is the stata code to merge back the original file\n",
    "\n",
    "use \"individual.dta\", clear\n",
    "\n",
    "merge n:1 id year using \"temp_csv.dta\"\n",
    "save \"individual.dta\", replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
