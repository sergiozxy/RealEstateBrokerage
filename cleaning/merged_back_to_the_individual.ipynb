{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import glob\n",
    "from shapely import wkt\n",
    "working_dir = r\"E:\\umich\\RealEstateBrokerage-main\"\n",
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"final_8_2_individual.csv\")\n",
    "df = pd.read_stata(\"for-analysis-with-dummy(should drop).dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns = ['geometry_x', 'geometry_y'], inplace = True)\n",
    "data = gpd.GeoDataFrame(data, geometry = gpd.points_from_xy(data.new_lng, data.new_lat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to extract key information that we will use in our regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to merge the two dataframes together\n",
    "columns = df.columns.tolist()\n",
    "with open('columns.md', 'w') as file:\n",
    "    for column in columns:\n",
    "        file.write(f\"- {column}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\n",
    "    \"village\", \"year\", \"region\", \"id\", \"unique_key\", \"nearest_store_indices\",\n",
    "    \"nearest_store_distances\", \"label\", \"lianjia_410\", \"broker_410\", \"hhi\", \"post3\", \"post2\",\n",
    "    \"post1\", \"entry\", \"pre1\", \"pre2\", \"pre3\", \"year_city_format\", \"beke_410\", \"bs_code\",\n",
    "    \"district_id\", \"treated\", \"density\", \"density_5\", \"lj_ratio\", \"density_1k\", \"diff_ratio\",\n",
    "    \"ln_watch_people\", \"non_watch\", \"non_nego\", \"non_online_effect\", \"city_id\", \"treatment\",\n",
    "    \"treatment_yearx1\", \"treatment_yearx2\", \"treatment_yearx3\", \"treatment_yearx4\", \"treatment_yearx5\",\n",
    "    \"treatment_yearx6\", \"treatment_yearx7\", \"avg_watch_time\", \"to_keep\"\n",
    "]\n",
    "\n",
    "dataframe = df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to conduct the results together\n",
    "des = pd.merge(data, dataframe, on = ['village', 'year'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "floor_ratio             0\n",
      "green_ratio             0\n",
      "nego_times              0\n",
      "lead_times              0\n",
      "building_type           0\n",
      "                    ...  \n",
      "treatment_yearx5    53331\n",
      "treatment_yearx6    53331\n",
      "treatment_yearx7    53331\n",
      "avg_watch_time      53331\n",
      "to_keep             53331\n",
      "Length: 111, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(des.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1831978\n"
     ]
    }
   ],
   "source": [
    "print(len(des))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to merge the two dataframes together\n",
    "columns = des.columns.tolist()\n",
    "with open('columns.md', 'w') as file:\n",
    "    for column in columns:\n",
    "        file.write(f\"- {column}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the data contains the samples from Xi'an and we need to drop them so we can directly drop the samples that have null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "des.dropna(subset = ['treatment'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "des.reset_index(drop = True, inplace = True)\n",
    "des.to_csv('final_individual.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
